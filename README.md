# AIPI - XAI | Adversarial Patches

## Author: Yufan Ai

### Overview
This repository contains the code and documentation for creating an adversarial patch aimed at deceiving the ResNet34 model, which is pre-trained on ImageNet. The objective of this assignment is to explore the effectiveness of adversarial patches and demonstrate how they can be used to manipulate model predictions in a controlled environment. The adversarial patch is tested on a real-world image from a fashion brand, with the intent of creating a visually subtle yet effective attack.

### Getting Started

To run the notebook, follow these steps:

1. Clone this repository to your local machine:
   ```bash
   git clone https://github.com/aiyufan3/AIPI-XAI-Adversarial-Patches.git
2. Navigate to the repository directory:
cd yourRepoName

4. Open the Colab notebook: [Open in Colab](https://colab.research.google.com/gist/aiyufan3/e9ef6b5474106b345647b015e07fc1f7/aipi-assignment-2.ipynb)
