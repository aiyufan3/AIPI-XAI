# AIPI - XAI | Adversarial Patches

## Author: Yufan Ai

### Overview
This repository contains the code and documentation for creating an adversarial patch aimed at deceiving the ResNet34 model, which is pre-trained on ImageNet. The objective of this assignment is to explore the effectiveness of adversarial patches and demonstrate how they can be used to manipulate model predictions in a controlled environment. The adversarial patch is tested on a real-world image from a fashion brand, with the intent of creating a visually subtle yet effective attack.

## Getting Started

To get started, you can open the notebook in Google Colab by clicking the link below:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1aZGfIlrOnx4wOd0ZBtRdt3ih3AT1vW27?usp=sharing#scrollTo=eHZGuy4DUNqy)


### Prerequisites

Ensure you have the following libraries installed. You can do this by running the command:

```bash
pip install -r requirements.txt

